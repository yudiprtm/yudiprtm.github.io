<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>vision | Fadhil Ginting</title>
    <link>https://mfadhilgtg.github.io/tags/vision/</link>
      <atom:link href="https://mfadhilgtg.github.io/tags/vision/index.xml" rel="self" type="application/rss+xml" />
    <description>vision</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 15 Jun 2019 09:20:33 +0100</lastBuildDate>
    <image>
      <url>https://mfadhilgtg.github.io/img/icon-192.png</url>
      <title>vision</title>
      <link>https://mfadhilgtg.github.io/tags/vision/</link>
    </image>
    
    <item>
      <title>TextVLAD</title>
      <link>https://mfadhilgtg.github.io/project/textvlad/</link>
      <pubDate>Sat, 15 Jun 2019 09:20:33 +0100</pubDate>
      <guid>https://mfadhilgtg.github.io/project/textvlad/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi Camera Deep Tracking and Mapping</title>
      <link>https://mfadhilgtg.github.io/project/deeptam/</link>
      <pubDate>Wed, 15 May 2019 09:20:18 +0100</pubDate>
      <guid>https://mfadhilgtg.github.io/project/deeptam/</guid>
      <description>&lt;p&gt;Visual Odometry methods based on classical 3D geometry have been around for years, using either indirect feature matching or direct visual error minimization. Lately,learning-based methods that combine both matching and geometry estimation in a single network have achieved impressive results. One such method is DeepTAM. Further, it has been shown that classical methods benefit from the extended field of view provided by using multiple cameras. However, these setups have been ignored by current learning-based methods.&lt;/p&gt;

&lt;p&gt;In this work, we extend the existing DeepTAM pipeline to leverage a multi-camera setup with known geometry. We demonstrate the generalizability of DeepTAM to other monocular setups and highlight the scenarios in which it performs poorly. We show the efficacy of our proposed multi-camera VO pipeline to receive better pose estimates using experiments based on simulation.&lt;/p&gt;

&lt;p&gt;Contributors: Mayank Mittal, Rohit Suri, Fadhil Ginting, Parker Ewen&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/surirohit/multi-camera-deeptam&#34; target=&#34;_blank&#34;&gt;https://github.com/surirohit/multi-camera-deeptam&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Magic Leap Mixed Reality for Healthcare Application</title>
      <link>https://mfadhilgtg.github.io/project/magicleap/</link>
      <pubDate>Fri, 01 Mar 2019 07:33:13 +0100</pubDate>
      <guid>https://mfadhilgtg.github.io/project/magicleap/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
